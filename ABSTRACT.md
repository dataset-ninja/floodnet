The **FloodNet 2021: A High Resolution Aerial Imagery Dataset for Post Flood Scene Understanding** provides high-resolution UAS imageries with detailed semantic annotation regarding the damages. To advance the damage assessment process for post-disaster scenarios, the authors of the dataset presented a unique challenge considering classification, semantic segmentation, and visual question answering highlighting the UAS imagery-based FloodNet dataset. The Challenge has two tracks: 1) Image Classification and Semantic Segmentation; and 2) Visual Question Answering.

Frequent, and increasingly severe, natural disasters threaten human health, infrastructure, and natural systems. The provision of accurate, timely, and understandable information has the potential to revolutionize disaster management. For quick response and recovery on a large scale, after a natural disaster such as a hurricane, access to aerial images is critically important for the response team. The emergence of small unmanned aerial systems (UAS) along with inexpensive sensors presents the opportunity to collect thousands of images after each natural disaster with high flexibility and easy maneuverability for rapid response and recovery. Moreover, UAS can access hard-to-reach areas and perform data collection tasks that can be unsafe for humans if not impossible. Despite all these advancements and efforts to collect such large datasets, analyzing them and extracting meaningful information remains a significant challenge in scientific communities.

The data was collected with a small UAS platform, DJI Mavic Pro quadcopters, after Hurricane Harvey. The whole dataset has 2343 images, divided into training (~60%), validation (~20%), and test (~20%) sets.

For Track 1 (Semi-supervised Classification and Semantic Segmentation), in the training set, there are around 400 labeled images (~25% of the training set) and around 1050 unlabeled images (~75% of the training set). For Track 2 (Supervised VQA), in the training set, there are around 1450 images and there are a total of 4511 image-question pairs.

The presented dataset contains annotations from **Track 1**. In this track, participants are required to complete two semi-supervised tasks. The first task is image classification, and the second task is semantic segmentation.

1. Semi-Supervised Classification: Classification for the FloodNet dataset requires classifying the images into ***flooded*** and ***non-flooded*** classes. Only a few of the training images have their labels available, while most of the training images are unlabeled.
2. Semi-Supervised Semantic Segmentation: The semantic segmentation labels include: 1) *background*, 2) *building flooded*, 3) *building non-flooded*, 4) *road flooded*, 5) *road non-flooded*, 6) *water*, 7) *tree*, 8) *vehicle*, 9) *pool*, 10) *grass*. Only a small portion of the training images have their corresponding masks available.

<i>Please note, that some masks in the dataset are cropped relatively to the original image.</i>
